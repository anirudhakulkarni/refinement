__all__ = ['negative_entropy','History','crl_accuracy']
import re
import numpy as np
import torch
import torch.nn.functional as F

# rank target entropy
def negative_entropy(data, normalize=False, max_value=None):
    softmax = F.softmax(data, dim=1)
    log_softmax = F.log_softmax(data, dim=1)
    entropy = softmax * log_softmax
    entropy = -1.0 * entropy.sum(dim=1)
    # normalize [0 ~ 1]
    if normalize:
        normalized_entropy = entropy / max_value
        return -normalized_entropy

    return -entropy

# correctness history class
class History(object):
    def __init__(self, n_data):
        self.correctness = np.zeros((n_data))
        self.confidence = np.zeros((n_data))
        self.max_correctness = 1
        self.epoch=0

    # correctness update
    def correctness_update(self, data_idx, correctness, output):
        probs = torch.nn.functional.softmax(output, dim=1)
        confidence, _ = probs.max(dim=1)
        data_idx = data_idx.cpu().numpy()

        self.correctness[data_idx] += correctness.cpu().numpy()
        self.confidence[data_idx] = confidence.cpu().detach().numpy()

    # max correctness update
    def max_correctness_update(self):
        print("max_correctness:",self.max_correctness,"epoch:",self.epoch)
        if self.epoch > 1:
            self.max_correctness += 1
        self.epoch+=1

    # correctness normalize (0 ~ 1) range
    def correctness_normalize(self, data):
        data_min = self.correctness.min()
        data_max = float(self.max_correctness)
        returnval=(data - data_min) / (data_max - data_min)
        if not (returnval.all()<=1.0 and returnval.all()>=0.0 ):
            print(returnval)
        return returnval

    # get target & margin
    def get_target_margin(self, data_idx1, data_idx2):
        # print("getting target margin")
        data_idx1 = data_idx1.cpu().numpy()
        cum_correctness1 = self.correctness[data_idx1]
        cum_correctness2 = self.correctness[data_idx2]
        # normalize correctness values
        cum_correctness1 = self.correctness_normalize(cum_correctness1)
        cum_correctness2 = self.correctness_normalize(cum_correctness2)
        # make target pair
        n_pair = len(data_idx1)
        # print(len(cum_correctness1),len(data_idx1))
        # print("Check:",cum_correctness1== cum_correctness1[:n_pair])
        target1 = cum_correctness1[:n_pair]
        target2 = cum_correctness2[:n_pair]
        # np.testing.assert_array_equal(target1,cum_correctness1)
        # np.testing.assert_array_equal(target2,cum_correctness2)
        
        # calc target
        greater = np.array(target1 > target2, dtype='float')
        less = np.array(target1 < target2, dtype='float') * (-1)

        target = greater + less
        target = torch.from_numpy(target).float().cuda()
        # calc margin
        margin = abs(target1 - target2)
        # margin = target1 - target2
        margin = torch.from_numpy(margin).float().cuda()
        # print("Got target margin")
        return target, margin


def crl_accuracy(output, target, topk=(1,)):
    """Computes the precision@k for the specified values of k"""
    maxk = max(topk)
    batch_size = target.size(0)

    _, pred = output.topk(maxk, 1, True, True)
    pred = pred.t()
    correct = pred.eq(target.view(1, -1).expand_as(pred))

    res = []
    for k in topk:
        correct_k = correct[:k].view(-1).float().sum(0)
        res.append(correct_k.mul_(100.0 / batch_size))
    return res[0], correct.squeeze()

